# Spotter Takehome Assessment
## Just click on the Sr DE Assessment.ipynb 
## You can read through it.  It's pyspark code that will run in any databricks cluster.   There's no need to run it.  You can see the questions and the code.  
## If you open in an IDE that's running copilot, you can certainly have copilot or any other LLM help you in understanding the code. 

## This is just an example of my knowledge of pyspark and databricks.   There's optimizations that are done both in the pyspark code and also through config settings in the databricks runtime. 

## If you're interested to try yourself; You can sign up for the community eddition of databricks, upload the .ipynb and run the code in databricks.   This is a good challenge to learn how to code in spark on top of databricks. 

## You can always contact mark for help markcosciello@yahoo.com

# Spotter Takehome Assessment

## Overview

This repository contains a take-home assessment demonstrating my knowledge of **PySpark** and **Databricks**.

## How to Use

- Open the notebook titled `Sr DE Assessment.ipynb`.
- You can read through the notebook without running it â€” it contains PySpark code that will execute in any Databricks cluster.
- The notebook includes both the questions and the corresponding code.

## Notes

- If you're using an IDE with GitHub Copilot or another LLM, feel free to use it to help understand the code.
- The notebook showcases optimizations applied both in the PySpark logic and through Databricks runtime configuration settings.

## Try It Yourself

If you're interested in running the code:
- You can sign up for the **Databricks Community Edition**.
- Upload the `.ipynb` file and run it directly in a Databricks notebook.
- This is a great hands-on challenge to learn how to work with Spark on Databricks.

## Contact

If you have any questions or would like to discuss the assessment, feel free to reach out:

**Mark Cosciello**  
ðŸ“§ markcosciello@yahoo.com
