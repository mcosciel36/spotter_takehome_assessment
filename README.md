# spotter_takehome_assessment
## Just click on the Sr DE Assessment.ipynb 
## You can read through it.  It's pyspark code that will run in any databricks cluster.   There's no need to run it.  You can see the questions and the code.  
## If you open in an IDE that's running copilot, you can certainly have copilot or any other LLM help you in understanding the code. 

## This is just an example of my knowledge of pyspark and databricks.   There's optimizations that are done both in the pyspark code and also through config settings in the databricks runtime. 

## If you're interested to try yourself; You can sign up for the community eddition of databricks, upload the .ipynb and run the code in databricks.   This is a good challenge to learn how to code in spark on top of databricks. 

## You can always contact mark for help markcosciello@yahoo.com
